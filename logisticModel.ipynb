{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08792bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "     |████████████████████████████████| 292 kB 1.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.23 in ./hsd_venv/lib/python3.9/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.15 in ./hsd_venv/lib/python3.9/site-packages (from seaborn) (1.21.4)\n",
      "Requirement already satisfied: scipy>=1.0 in ./hsd_venv/lib/python3.9/site-packages (from seaborn) (1.7.3)\n",
      "Collecting matplotlib>=2.2\n",
      "  Downloading matplotlib-3.5.0-cp39-cp39-macosx_10_9_x86_64.whl (7.3 MB)\n",
      "     |████████████████████████████████| 7.3 MB 3.8 MB/s            \n",
      "\u001b[?25hCollecting setuptools-scm>=4\n",
      "  Downloading setuptools_scm-6.3.2-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./hsd_venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.4.0-cp39-cp39-macosx_10_10_x86_64.whl (3.0 MB)\n",
      "     |████████████████████████████████| 3.0 MB 4.3 MB/s            \n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp39-cp39-macosx_10_9_x86_64.whl (61 kB)\n",
      "     |████████████████████████████████| 61 kB 1.2 MB/s             \n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./hsd_venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./hsd_venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.28.2-py3-none-any.whl (880 kB)\n",
      "     |████████████████████████████████| 880 kB 6.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in ./hsd_venv/lib/python3.9/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in ./hsd_venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: setuptools in ./hsd_venv/lib/python3.9/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (58.5.3)\n",
      "Collecting tomli>=1.0.0\n",
      "  Downloading tomli-1.2.2-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: tomli, setuptools-scm, pillow, kiwisolver, fonttools, cycler, matplotlib, seaborn\n",
      "Successfully installed cycler-0.11.0 fonttools-4.28.2 kiwisolver-1.3.2 matplotlib-3.5.0 pillow-8.4.0 seaborn-0.11.2 setuptools-scm-6.3.2 tomli-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b33f2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b758242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv(\"data/clean/git_twitter.csv\", index_col = \"Unnamed: 0\")\n",
    "reddit_df = pd.read_csv(\"data/clean/reddit.csv\", index_col = \"Unnamed: 0\")\n",
    "reddit_df = reddit_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c38de830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'listening to sad songs on a monday morning otw to work is sad'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.Data[31959]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa123c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Muthukrishna/Desktop/NLP-Project/hsd_venv/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of Class')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(twitter_df['Label'], palette='Set3').set_title('Distribution of Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39fb4c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40a42a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(\"data/github_twitter/train.csv\", index_col = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "738d8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean all data\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    # make text lowercase\n",
    "    text = text.lower()\n",
    "    # removing text within brackets\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    # removing text within parentheses\n",
    "    text = re.sub('\\(.*?\\)', '', text)\n",
    "    # removing numbers\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    # if there's more than 1 whitespace, then make it just 1\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    # if there's a new line, then make it a whitespace\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    # removing any quotes\n",
    "    text = re.sub('\\\"+', '', text)\n",
    "    # removing &amp;\n",
    "    text = re.sub('(\\&amp\\;)', '', text)\n",
    "    # removing any usernames\n",
    "    text = re.sub('(@[^\\s]+)', '', text)\n",
    "    # removing any hashtags\n",
    "    text = re.sub('(#[^\\s]+)', '', text)\n",
    "    # remove `rt` for retweet\n",
    "    text = re.sub('(rt)', '', text)\n",
    "    # string.punctuation is a string of all punctuation marks\n",
    "    # so this gets rid of all punctuation\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # getting rid of `httptco`\n",
    "    text = re.sub('(httptco)', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "cleantweet = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3f1102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df['clean_data'] = twitter_df['Data'].apply(cleantweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cccc2d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Data</th>\n",
       "      <th>clean_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so...</td>\n",
       "      <td>when a father is dysfunctional and is so self...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i cant use...</td>\n",
       "      <td>thanks for  credit i cant use cause they don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>birthday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>i love u take with u all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu</td>\n",
       "      <td>ate  isz that youuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to w...</td>\n",
       "      <td>to see nina turner on the airwaves trying to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "      <td>vandalised in in   condemns act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "      <td>thank you  for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label                                               Data  \\\n",
       "0          0  @user when a father is dysfunctional and is so...   \n",
       "1          0  @user @user thanks for #lyft credit i cant use...   \n",
       "2          0                              birthday your majesty   \n",
       "3          0  #model   i love u take with u all the time in ...   \n",
       "4          0             factsguide: society now    #motivation   \n",
       "...      ...                                                ...   \n",
       "31957      0                           ate @user isz that youuu   \n",
       "31958      0  to see nina turner on the airwaves trying to w...   \n",
       "31959      0  listening to sad songs on a monday morning otw...   \n",
       "31960      1  @user #sikh #temple vandalised in in #calgary,...   \n",
       "31961      0                     thank you @user for you follow   \n",
       "\n",
       "                                              clean_data  \n",
       "0       when a father is dysfunctional and is so self...  \n",
       "1        thanks for  credit i cant use cause they don...  \n",
       "2                                    bihday your majesty  \n",
       "3                i love u take with u all the time in ur  \n",
       "4                                factsguide society now   \n",
       "...                                                  ...  \n",
       "31957                                ate  isz that youuu  \n",
       "31958  to see nina turner on the airwaves trying to w...  \n",
       "31959  listening to sad songs on a monday morning otw...  \n",
       "31960                    vandalised in in   condemns act  \n",
       "31961                          thank you  for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba2b2db",
   "metadata": {},
   "source": [
    "## Tokenizing and removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9ade898",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = twitter_df['clean_data']\n",
    "Y = twitter_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "247797ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93978541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting NLTK stop words as `stop_words`\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c9c3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(text):\n",
    "    \"\"\"tokenize text in each column and remove stop words\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
    "    return stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cdf10f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/Muthukrishna/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13916a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = list(map(process_tweet, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e90c4559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22207"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_vocab = set()\n",
    "for comment in processed_data:\n",
    "    total_vocab.update(comment)\n",
    "len(total_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1536ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9f433f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('day', 2026),\n",
       " ('happy', 1575),\n",
       " ('love', 1205),\n",
       " ('im', 1148),\n",
       " ('u', 1137),\n",
       " ('time', 1084),\n",
       " ('like', 973),\n",
       " ('today', 939),\n",
       " ('new', 917),\n",
       " ('get', 915),\n",
       " ('cant', 808),\n",
       " ('people', 803),\n",
       " ('good', 790),\n",
       " ('one', 774),\n",
       " ('see', 753),\n",
       " ('dont', 729),\n",
       " ('life', 712),\n",
       " ('go', 649),\n",
       " ('want', 647),\n",
       " ('take', 615),\n",
       " ('fathers', 595),\n",
       " ('bihday', 584),\n",
       " ('got', 574),\n",
       " ('make', 533),\n",
       " ('need', 507),\n",
       " ('bull', 504),\n",
       " ('way', 504),\n",
       " ('going', 488),\n",
       " ('great', 484),\n",
       " ('us', 475),\n",
       " ('days', 475),\n",
       " ('best', 474),\n",
       " ('first', 468),\n",
       " ('work', 468),\n",
       " ('really', 462),\n",
       " ('wait', 462),\n",
       " ('thankful', 456),\n",
       " ('ur', 454),\n",
       " ('back', 442),\n",
       " ('know', 430),\n",
       " ('tomorrow', 419),\n",
       " ('never', 408),\n",
       " ('week', 408),\n",
       " ('think', 395),\n",
       " ('morning', 387),\n",
       " ('world', 381),\n",
       " ('feel', 374),\n",
       " ('much', 369),\n",
       " ('right', 365),\n",
       " ('well', 364),\n",
       " ('sad', 349),\n",
       " ('youre', 340),\n",
       " ('even', 337),\n",
       " ('always', 334),\n",
       " ('last', 332),\n",
       " ('night', 329),\n",
       " ('weekend', 329),\n",
       " ('come', 329),\n",
       " ('next', 324),\n",
       " ('still', 322),\n",
       " ('finally', 319),\n",
       " ('year', 307),\n",
       " ('find', 303),\n",
       " ('thank', 301),\n",
       " ('things', 300),\n",
       " ('friday', 297),\n",
       " ('via', 287),\n",
       " ('look', 287),\n",
       " ('many', 287),\n",
       " ('makes', 284),\n",
       " ('ready', 283),\n",
       " ('tonight', 279),\n",
       " ('little', 269),\n",
       " ('thanks', 268),\n",
       " ('na', 268),\n",
       " ('looking', 268),\n",
       " ('everyone', 262),\n",
       " ('live', 259),\n",
       " ('another', 258),\n",
       " ('getting', 257),\n",
       " ('ever', 254),\n",
       " ('would', 254),\n",
       " ('home', 252),\n",
       " ('old', 251),\n",
       " ('family', 251),\n",
       " ('show', 250),\n",
       " ('friends', 245),\n",
       " ('climb', 245),\n",
       " ('watch', 238),\n",
       " ('say', 238),\n",
       " ('man', 237),\n",
       " ('sta', 236),\n",
       " ('bear', 235),\n",
       " ('beautiful', 233),\n",
       " ('amazing', 232),\n",
       " ('city', 231),\n",
       " ('stop', 230),\n",
       " ('feeling', 228),\n",
       " ('made', 227),\n",
       " ('whatever', 227),\n",
       " ('every', 227),\n",
       " ('ive', 223),\n",
       " ('sunday', 222),\n",
       " ('might', 222),\n",
       " ('thats', 220),\n",
       " ('polar', 216),\n",
       " ('game', 215),\n",
       " ('excited', 213),\n",
       " ('girl', 208),\n",
       " ('keep', 207),\n",
       " ('coming', 203),\n",
       " ('help', 203),\n",
       " ('may', 202),\n",
       " ('hope', 202),\n",
       " ('someone', 201),\n",
       " ('trump', 199),\n",
       " ('years', 199),\n",
       " ('angry', 197),\n",
       " ('nothing', 195),\n",
       " ('around', 193),\n",
       " ('let', 192),\n",
       " ('god', 192),\n",
       " ('better', 191),\n",
       " ('free', 190),\n",
       " ('found', 189),\n",
       " ('summer', 189),\n",
       " ('long', 188),\n",
       " ('news', 185),\n",
       " ('guys', 185),\n",
       " ('please', 183),\n",
       " ('follow', 183),\n",
       " ('big', 182),\n",
       " ('pay', 181),\n",
       " ('white', 180),\n",
       " ('music', 180),\n",
       " ('black', 179),\n",
       " ('hate', 179),\n",
       " ('direct', 178),\n",
       " ('orlando', 178),\n",
       " ('dominate', 175),\n",
       " ('done', 175),\n",
       " ('n', 175),\n",
       " ('dad', 175),\n",
       " ('believe', 174),\n",
       " ('soon', 173),\n",
       " ('thing', 173),\n",
       " ('two', 172),\n",
       " ('something', 170),\n",
       " ('didnt', 170),\n",
       " ('school', 169),\n",
       " ('away', 167),\n",
       " ('without', 165),\n",
       " ('watching', 164),\n",
       " ('yes', 163),\n",
       " ('forward', 163),\n",
       " ('miss', 162),\n",
       " ('weeks', 161),\n",
       " ('waiting', 160),\n",
       " ('smile', 160),\n",
       " ('bad', 158),\n",
       " ('attack', 158),\n",
       " ('place', 157),\n",
       " ('end', 157),\n",
       " ('real', 157),\n",
       " ('lost', 155),\n",
       " ('hea', 155),\n",
       " ('friend', 154),\n",
       " ('happiness', 153),\n",
       " ('playing', 152),\n",
       " ('lol', 152),\n",
       " ('fun', 152),\n",
       " ('nice', 151),\n",
       " ('racing', 151),\n",
       " ('bing', 151),\n",
       " ('check', 151),\n",
       " ('give', 151),\n",
       " ('play', 151),\n",
       " ('oh', 150),\n",
       " ('yeah', 150),\n",
       " ('bong', 150),\n",
       " ('true', 150),\n",
       " ('wish', 149),\n",
       " ('girls', 148),\n",
       " ('doesnt', 148),\n",
       " ('could', 148),\n",
       " ('left', 146),\n",
       " ('video', 146),\n",
       " ('lt', 145),\n",
       " ('team', 145),\n",
       " ('person', 145),\n",
       " ('kids', 143),\n",
       " ('ill', 143),\n",
       " ('gon', 142),\n",
       " ('racist', 140),\n",
       " ('baby', 139),\n",
       " ('saturday', 138),\n",
       " ('face', 138),\n",
       " ('lot', 138),\n",
       " ('yet', 137),\n",
       " ('r', 136)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# morphing `processed_data` into a readable list\n",
    "flat_filtered = [item for sublist in processed_data for item in sublist]\n",
    "# getting frequency distribution\n",
    "clean_corpus_freqdist = FreqDist(flat_filtered)\n",
    "# top 20 words in cleaned corpus\n",
    "clean_corpus_freqdist.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba745733",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = pd.read_csv(\"/Users/Muthukrishna/Desktop/labeled_data.csv\", index_col = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2426016c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25291</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25292</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25294</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25295</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25296</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  hate_speech  offensive_language  neither  class  \\\n",
       "0          3            0                   0        3      2   \n",
       "1          3            0                   3        0      1   \n",
       "2          3            0                   3        0      1   \n",
       "3          3            0                   2        1      1   \n",
       "4          6            0                   6        0      1   \n",
       "...      ...          ...                 ...      ...    ...   \n",
       "25291      3            0                   2        1      1   \n",
       "25292      3            0                   1        2      2   \n",
       "25294      3            0                   3        0      1   \n",
       "25295      6            0                   6        0      1   \n",
       "25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "25291  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "25292  you've gone and broke the wrong heart baby, an...  \n",
       "25294  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "25295              youu got wild bitches tellin you lies  \n",
       "25296  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7255195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter['label'] = twitter['class'].replace(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f443189",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter['label'] = twitter['class'].replace(0, 1)\n",
    "twitter['label'] = twitter['class'].replace(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "15c85993",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter['clean_tweets'] = twitter['tweet'].apply(cleantweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "118af3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_twitter = twitter[['clean_tweets', 'label']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4064fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_twitter['clean_tweets']\n",
    "target = clean_twitter['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb545e42",
   "metadata": {},
   "source": [
    "### Before Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca010ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfiltered_tokens(text):\n",
    "    dirty_tokens = nltk.word_tokenize(text)\n",
    "    return dirty_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "534dc935",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilterd_data = list(map(unfiltered_tokens, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0cfafc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_unfiltered = [item for sublist in unfilterd_data for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "741a6441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 9476),\n",
       " ('bitch', 8227),\n",
       " ('i', 7538),\n",
       " ('the', 7168),\n",
       " ('you', 6120),\n",
       " ('to', 5332),\n",
       " ('and', 3951),\n",
       " ('my', 3579),\n",
       " ('that', 3528),\n",
       " ('bitches', 3083),\n",
       " ('in', 3051),\n",
       " ('is', 2909),\n",
       " ('like', 2766),\n",
       " ('me', 2764),\n",
       " ('of', 2544),\n",
       " ('on', 2518),\n",
       " ('be', 2375),\n",
       " ('hoes', 2368),\n",
       " ('this', 2149),\n",
       " ('for', 2119)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting frequency distribution\n",
    "dirty_corpus_freqdist = FreqDist(flat_unfiltered)\n",
    "# top 20 words in the corpus\n",
    "dirty_corpus_freqdist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b570b26c",
   "metadata": {},
   "source": [
    "## Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9b8aaa58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20277"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "processed_data = list(map(process_tweet, data))\n",
    "total_vocab = set()\n",
    "for comment in processed_data:\n",
    "    total_vocab.update(comment)\n",
    "len(total_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75871829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bitch', 8227),\n",
       " ('bitches', 3083),\n",
       " ('like', 2766),\n",
       " ('hoes', 2368),\n",
       " ('pussy', 2099),\n",
       " ('im', 2061),\n",
       " ('hoe', 1906),\n",
       " ('dont', 1749),\n",
       " ('got', 1597),\n",
       " ('ass', 1570),\n",
       " ('get', 1428),\n",
       " ('fuck', 1411),\n",
       " ('u', 1280),\n",
       " ('shit', 1262),\n",
       " ('nigga', 1198),\n",
       " ('aint', 1158),\n",
       " ('trash', 1142),\n",
       " ('lol', 1074),\n",
       " ('know', 806),\n",
       " ('niggas', 791)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# morphing `processed_data` into a readable list\n",
    "flat_filtered = [item for sublist in processed_data for item in sublist]\n",
    "# getting frequency distribution\n",
    "clean_corpus_freqdist = FreqDist(flat_filtered)\n",
    "# top 20 words in cleaned corpus\n",
    "clean_corpus_freqdist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbcde5f",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "787ede52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/Muthukrishna/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa736c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a0eb976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list with all lemmatized outputs\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "lemmatized_output = []\n",
    "\n",
    "for listy in processed_data:\n",
    "    lemmed = ' '.join([lemmatizer.lemmatize(w) for w in listy])\n",
    "    lemmatized_output.append(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de617237",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lem = lemmatized_output\n",
    "y_lem = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2c349a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.8.1-py3-none-any.whl (189 kB)\n",
      "     |████████████████████████████████| 189 kB 5.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in ./hsd_venv/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in ./hsd_venv/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in ./hsd_venv/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./hsd_venv/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.21.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./hsd_venv/lib/python3.9/site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (3.0.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.8.1 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86ce1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from collections import Counter\n",
    "from sklearn import metrics, utils, model_selection, svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0a08d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lem, y_lem, test_size=0.20, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca85a1b",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5cffad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d7f0adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating tf_idf vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words= stop_words, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ccc4a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming tokenized data into sparse matrix format with 20K stored elements\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1116f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Elements in Vectorized Articles: 13.364420457984465\n",
      "Percentage of columns containing ZERO: 0.9998720483637183\n"
     ]
    }
   ],
   "source": [
    "# taking a quick look at the non zero elements\n",
    "non_zero_cols = X_train_tfidf.nnz / float(X_train_tfidf.shape[0])\n",
    "print(\"Average Number of Non-Zero Elements in Vectorized Articles: {}\".format(non_zero_cols))\n",
    "percent_sparse = 1 - (non_zero_cols / float(X_train_tfidf.shape[1]))\n",
    "print('Percentage of columns containing ZERO: {}'.format(percent_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e6c843c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_baseline = LogisticRegression(penalty='l2', class_weight='balanced', random_state=20)\n",
    "# class_weight='balanced' actually didn't impact the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33015784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.18 s, sys: 1.22 s, total: 5.4 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_reg_baseline.fit(X_train_tfidf, y_train)\n",
    "log_reg_test_preds = log_reg_baseline.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "538caa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(precision, recall, f1_score, f1_weighted):\n",
    "    \"\"\"prints out evaluation metrics for a model\"\"\"\n",
    "    print('Testing Set Evaluation Metrics:')\n",
    "    print('Precision: {:.4}'.format(precision))\n",
    "    print('Recall: {:.4}'.format(recall))\n",
    "    print('F1 Score: {:.4}'.format(f1_score))\n",
    "    print('Weighted F1 Score: {:.4}'.format(f1_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "415b479d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Evaluation Metrics:\n",
      "Precision: 0.9593\n",
      "Recall: 0.891\n",
      "F1 Score: 0.9239\n",
      "Weighted F1 Score: 0.8899\n"
     ]
    }
   ],
   "source": [
    "log_reg_precision = precision_score(y_test, log_reg_test_preds)\n",
    "log_reg_recall = recall_score(y_test, log_reg_test_preds)\n",
    "log_reg_f1_score = f1_score(y_test, log_reg_test_preds)\n",
    "log_reg_f1_weighted = f1_score(y_test, log_reg_test_preds, average='weighted')\n",
    "\n",
    "# printing scores\n",
    "evaluation(log_reg_precision, log_reg_recall, log_reg_f1_score, log_reg_f1_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "559b03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "46b02b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8856163001815615"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, log_reg_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d56d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
