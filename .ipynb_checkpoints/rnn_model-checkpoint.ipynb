{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0194f517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.7.0-cp39-cp39-macosx_10_11_x86_64.whl (207.1 MB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.6.0-cp39-cp39-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-12.0.0-py2.py3-none-macosx_10_9_x86_64.whl (12.2 MB)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Using cached tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "Collecting wheel<1.0,>=0.32.0\n",
      "  Using cached wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in ./hsd_venv/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in ./hsd_venv/lib/python3.9/site-packages (from tensorflow) (1.21.4)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.0.1-py3-none-any.whl (22 kB)\n",
      "Collecting flatbuffers<3.0,>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.22.0-cp39-cp39-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.13.3-cp39-cp39-macosx_10_9_x86_64.whl (33 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-3.19.1-cp39-cp39-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting gast<0.5.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Using cached tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras<2.8,>=2.7.0rc0\n",
      "  Using cached keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.42.0-cp39-cp39-macosx_10_10_x86_64.whl (4.0 MB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./hsd_venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (57.0.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./hsd_venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.8.2-py3-none-any.whl (17 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./hsd_venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./hsd_venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./hsd_venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./hsd_venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, wheel, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-4.2.4 flatbuffers-2.0 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.42.0 h5py-3.6.0 importlib-metadata-4.8.2 keras-2.7.0 keras-preprocessing-1.1.2 libclang-12.0.0 markdown-3.3.6 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.8 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.22.0 termcolor-1.1.0 typing-extensions-4.0.1 werkzeug-2.0.2 wheel-0.37.0 wrapt-1.13.3 zipp-3.6.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/abishek/Desktop/One Drive (NYU)/OneDrive - nyu.edu/NYU Notes/Fall 2021/Natual Language Processing/Project Work/NLP-Project/hsd_venv/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8c3d8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "917593e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv(\"data/clean/git_twitter.csv\", index_col = \"Unnamed: 0\")\n",
    "reddit_df = pd.read_csv(\"data/clean/reddit.csv\", index_col = \"Unnamed: 0\")\n",
    "reddit_df = reddit_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3598ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df['Data'] = twitter_df['Data'].str.lower()\n",
    "reddit_df['Data'] = reddit_df['Data'].str.lower()\n",
    "twitter_df['Data'] = twitter_df['Data'].apply(lambda x: ' '.join([word.translate(table) for word in x.split()]))\n",
    "twitter_df['Data'] = twitter_df['Data'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "twitter_df['Data'] = twitter_df['Data'].apply(lambda x: ' '.join([porter.stem(word) for word in x.split()]))\n",
    "reddit_df['Data'] = reddit_df['Data'].apply(lambda x: ' '.join([word.translate(table) for word in x.split()]))\n",
    "reddit_df['Data'] = reddit_df['Data'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "reddit_df['Data'] = reddit_df['Data'].apply(lambda x: ' '.join([porter.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "497caeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = train_test_split(reddit_df, test_size=0.2, random_state=42, shuffle=True)\n",
    "(train, val) = train_test_split(train, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82e6b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train['Data'].to_numpy()\n",
    "test_sentences = test['Data'].to_numpy()\n",
    "val_sentences = val['Data'].to_numpy()\n",
    "\n",
    "train_labels = train['Label'].to_numpy()\n",
    "test_labels = test['Label'].to_numpy()\n",
    "val_labels = val['Label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85f0767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "oov_token = \"<oov>\"\n",
    "\n",
    "tokeniser = Tokenizer(num_words = vocab_size,oov_token = oov_token)\n",
    "tokeniser.fit_on_texts(train_sentences)\n",
    "word_index = tokeniser.word_index\n",
    "sequences = tokeniser.texts_to_sequences(train_sentences)\n",
    "padding = pad_sequences(sequences,maxlen=120,truncating='post')\n",
    "\n",
    "val_sequences = tokeniser.texts_to_sequences(val_sentences)\n",
    "val_padded = pad_sequences(val_sequences,maxlen=120,truncating='post')\n",
    "\n",
    "testing_sequences = tokeniser.texts_to_sequences(test_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=120,truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37972daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size,16,input_length=120),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units = 10,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units = 1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71a7339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "340/340 [==============================] - 2s 3ms/step - loss: 0.5651 - accuracy: 0.7066 - val_loss: 0.3755 - val_accuracy: 0.8587\n",
      "Epoch 2/10\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.2746 - accuracy: 0.8985 - val_loss: 0.3014 - val_accuracy: 0.8936\n",
      "Epoch 3/10\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.1660 - accuracy: 0.9449 - val_loss: 0.3175 - val_accuracy: 0.8863\n",
      "Epoch 4/10\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.1069 - accuracy: 0.9651 - val_loss: 0.3657 - val_accuracy: 0.8730\n",
      "Epoch 5/10\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.0687 - accuracy: 0.9797 - val_loss: 0.4121 - val_accuracy: 0.8752\n",
      "Epoch 6/10\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.0458 - accuracy: 0.9870 - val_loss: 0.4639 - val_accuracy: 0.8693\n",
      "Epoch 7/10\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.0326 - accuracy: 0.9914 - val_loss: 0.5069 - val_accuracy: 0.8690\n",
      "Epoch 8/10\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.0245 - accuracy: 0.9941 - val_loss: 0.5450 - val_accuracy: 0.8609\n",
      "Epoch 9/10\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.0188 - accuracy: 0.9955 - val_loss: 0.5762 - val_accuracy: 0.8601\n",
      "Epoch 10/10\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 0.6344 - val_accuracy: 0.8605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d234ca0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "simple_model.fit(padding,train_labels,epochs = 10,validation_data=(val_padded,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3b4b8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 - 0s - loss: 0.6538 - accuracy: 0.8525 - 146ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6538158059120178, 0.8525169491767883]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = simple_model.evaluate(testing_padded,  test_labels, verbose=2)\n",
    "print(\"The simple model gives us an accuracy of: \", output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "62a574ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size,16,input_length=120),\n",
    "    tf.keras.layers.SimpleRNN(units = 6, dropout=0.3, activation=\"tanh\"),\n",
    "    tf.keras.layers.Dense(units = 1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7f23be17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "340/340 [==============================] - 12s 32ms/step - loss: 0.5225 - accuracy: 0.7595 - val_loss: 0.3179 - val_accuracy: 0.9076\n",
      "Epoch 2/10\n",
      "340/340 [==============================] - 14s 40ms/step - loss: 0.2971 - accuracy: 0.8993 - val_loss: 0.2828 - val_accuracy: 0.9109\n",
      "Epoch 3/10\n",
      "340/340 [==============================] - 11s 33ms/step - loss: 0.2348 - accuracy: 0.9210 - val_loss: 0.2915 - val_accuracy: 0.9021\n",
      "Epoch 4/10\n",
      "340/340 [==============================] - 12s 34ms/step - loss: 0.1937 - accuracy: 0.9365 - val_loss: 0.2889 - val_accuracy: 0.9102\n",
      "Epoch 5/10\n",
      "340/340 [==============================] - 12s 35ms/step - loss: 0.1705 - accuracy: 0.9459 - val_loss: 0.3181 - val_accuracy: 0.8988\n",
      "Epoch 6/10\n",
      "340/340 [==============================] - 12s 37ms/step - loss: 0.1469 - accuracy: 0.9542 - val_loss: 0.3436 - val_accuracy: 0.8888\n",
      "Epoch 7/10\n",
      "340/340 [==============================] - 13s 37ms/step - loss: 0.1311 - accuracy: 0.9592 - val_loss: 0.3565 - val_accuracy: 0.8892\n",
      "Epoch 8/10\n",
      "340/340 [==============================] - 13s 37ms/step - loss: 0.1194 - accuracy: 0.9644 - val_loss: 0.3856 - val_accuracy: 0.8804\n",
      "Epoch 9/10\n",
      "340/340 [==============================] - 13s 38ms/step - loss: 0.1051 - accuracy: 0.9698 - val_loss: 0.3925 - val_accuracy: 0.8826\n",
      "Epoch 10/10\n",
      "340/340 [==============================] - 13s 38ms/step - loss: 0.0928 - accuracy: 0.9732 - val_loss: 0.3989 - val_accuracy: 0.8830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d777730>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "rnn_model.fit(padding,train_labels,epochs = 10,validation_data=(val_padded,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c9c373c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 - 1s - loss: 0.4302 - accuracy: 0.8728 - 583ms/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43023544549942017, 0.8728289604187012]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = rnn_model.evaluate(testing_padded,  test_labels, verbose=2)\n",
    "print(\"The Baseline RNN model gives us an accuracy of: \", output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "70bed676",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size,16,input_length=120),\n",
    "    tf.keras.layers.LSTM(units = 6, dropout=0.3, activation=\"tanh\"),\n",
    "    tf.keras.layers.Dense(units = 1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e77fc2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "340/340 [==============================] - 17s 44ms/step - loss: 0.5396 - accuracy: 0.7290 - val_loss: 0.3561 - val_accuracy: 0.8712\n",
      "Epoch 2/10\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.2948 - accuracy: 0.9104 - val_loss: 0.2825 - val_accuracy: 0.9102\n",
      "Epoch 3/10\n",
      "340/340 [==============================] - 16s 46ms/step - loss: 0.2141 - accuracy: 0.9341 - val_loss: 0.2746 - val_accuracy: 0.9128\n",
      "Epoch 4/10\n",
      "340/340 [==============================] - 17s 50ms/step - loss: 0.1746 - accuracy: 0.9476 - val_loss: 0.2752 - val_accuracy: 0.9113\n",
      "Epoch 5/10\n",
      "340/340 [==============================] - 18s 51ms/step - loss: 0.1612 - accuracy: 0.9495 - val_loss: 0.2830 - val_accuracy: 0.9172\n",
      "Epoch 6/10\n",
      "340/340 [==============================] - 19s 55ms/step - loss: 0.1406 - accuracy: 0.9574 - val_loss: 0.3154 - val_accuracy: 0.9017\n",
      "Epoch 7/10\n",
      "340/340 [==============================] - 19s 54ms/step - loss: 0.1266 - accuracy: 0.9623 - val_loss: 0.3212 - val_accuracy: 0.9039\n",
      "Epoch 8/10\n",
      "340/340 [==============================] - 19s 55ms/step - loss: 0.1096 - accuracy: 0.9704 - val_loss: 0.3319 - val_accuracy: 0.9003\n",
      "Epoch 9/10\n",
      "340/340 [==============================] - 19s 56ms/step - loss: 0.1022 - accuracy: 0.9709 - val_loss: 0.3703 - val_accuracy: 0.8885\n",
      "Epoch 10/10\n",
      "340/340 [==============================] - 19s 57ms/step - loss: 0.0982 - accuracy: 0.9729 - val_loss: 0.3859 - val_accuracy: 0.8819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12c9f2c10>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "lstm_model.fit(padding,train_labels,epochs = 10,validation_data=(val_padded,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a4632393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 - 1s - loss: 0.4122 - accuracy: 0.8752 - 914ms/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41222134232521057, 0.8751839995384216]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = lstm_model.evaluate(testing_padded,  test_labels, verbose=2)\n",
    "print(\"The LSTM model gives us an accuracy of: \", output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "de8df018",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size,16,input_length=120),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 6, dropout=0.3, activation=\"tanh\")),\n",
    "    tf.keras.layers.Dense(units = 1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a386cb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "340/340 [==============================] - 23s 59ms/step - loss: 0.5450 - accuracy: 0.7322 - val_loss: 0.3471 - val_accuracy: 0.8966\n",
      "Epoch 2/10\n",
      "340/340 [==============================] - 22s 66ms/step - loss: 0.2804 - accuracy: 0.9141 - val_loss: 0.2714 - val_accuracy: 0.9165\n",
      "Epoch 3/10\n",
      "340/340 [==============================] - 20s 58ms/step - loss: 0.2117 - accuracy: 0.9346 - val_loss: 0.2711 - val_accuracy: 0.9117\n",
      "Epoch 4/10\n",
      "340/340 [==============================] - 19s 57ms/step - loss: 0.1875 - accuracy: 0.9416 - val_loss: 0.2747 - val_accuracy: 0.9128\n",
      "Epoch 5/10\n",
      "340/340 [==============================] - 20s 59ms/step - loss: 0.1599 - accuracy: 0.9520 - val_loss: 0.2862 - val_accuracy: 0.9073\n",
      "Epoch 6/10\n",
      "340/340 [==============================] - 21s 61ms/step - loss: 0.1425 - accuracy: 0.9564 - val_loss: 0.2947 - val_accuracy: 0.9102\n",
      "Epoch 7/10\n",
      "340/340 [==============================] - 22s 64ms/step - loss: 0.1262 - accuracy: 0.9640 - val_loss: 0.3055 - val_accuracy: 0.9058\n",
      "Epoch 8/10\n",
      "340/340 [==============================] - 23s 68ms/step - loss: 0.1174 - accuracy: 0.9668 - val_loss: 0.3198 - val_accuracy: 0.9080\n",
      "Epoch 9/10\n",
      "340/340 [==============================] - 21s 62ms/step - loss: 0.1087 - accuracy: 0.9691 - val_loss: 0.3534 - val_accuracy: 0.8958\n",
      "Epoch 10/10\n",
      "340/340 [==============================] - 21s 63ms/step - loss: 0.1023 - accuracy: 0.9710 - val_loss: 0.3576 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12dbc5250>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_lstm_model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "bi_lstm_model.fit(padding,train_labels,epochs = 10,validation_data=(val_padded,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4da161dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 - 1s - loss: 0.3872 - accuracy: 0.8893 - 1s/epoch - 10ms/step\n",
      "The BI-LSTM model gives us an accuracy of:  0.8893141150474548\n"
     ]
    }
   ],
   "source": [
    "output = bi_lstm_model.evaluate(testing_padded,  test_labels, verbose=2)\n",
    "print(\"The BI-LSTM model gives us an accuracy of: \", output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c8cfa154",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size,16,input_length=120),\n",
    "    tf.keras.layers.GRU(units = 6, dropout=0.3, activation=\"tanh\"),\n",
    "    tf.keras.layers.Dense(units = 1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "69beb4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "340/340 [==============================] - 20s 55ms/step - loss: 0.5199 - accuracy: 0.7490 - val_loss: 0.2928 - val_accuracy: 0.9047\n",
      "Epoch 2/10\n",
      "340/340 [==============================] - 19s 57ms/step - loss: 0.2561 - accuracy: 0.9152 - val_loss: 0.2597 - val_accuracy: 0.9117\n",
      "Epoch 3/10\n",
      "340/340 [==============================] - 19s 57ms/step - loss: 0.2059 - accuracy: 0.9333 - val_loss: 0.2609 - val_accuracy: 0.9135\n",
      "Epoch 4/10\n",
      "340/340 [==============================] - 22s 65ms/step - loss: 0.1792 - accuracy: 0.9434 - val_loss: 0.2678 - val_accuracy: 0.9187\n",
      "Epoch 5/10\n",
      "340/340 [==============================] - 26s 76ms/step - loss: 0.1615 - accuracy: 0.9502 - val_loss: 0.2840 - val_accuracy: 0.9194\n",
      "Epoch 6/10\n",
      "340/340 [==============================] - 25s 75ms/step - loss: 0.1498 - accuracy: 0.9528 - val_loss: 0.2893 - val_accuracy: 0.9106\n",
      "Epoch 7/10\n",
      "340/340 [==============================] - 22s 66ms/step - loss: 0.1396 - accuracy: 0.9572 - val_loss: 0.2998 - val_accuracy: 0.9109\n",
      "Epoch 8/10\n",
      "340/340 [==============================] - 23s 67ms/step - loss: 0.1290 - accuracy: 0.9612 - val_loss: 0.3108 - val_accuracy: 0.9047\n",
      "Epoch 9/10\n",
      "340/340 [==============================] - 25s 74ms/step - loss: 0.1222 - accuracy: 0.9628 - val_loss: 0.3213 - val_accuracy: 0.9047\n",
      "Epoch 10/10\n",
      "340/340 [==============================] - 23s 69ms/step - loss: 0.1162 - accuracy: 0.9644 - val_loss: 0.3475 - val_accuracy: 0.8837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e8d3910>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "gru_model.fit(padding,train_labels,epochs = 10,validation_data=(val_padded,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "614acb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 - 1s - loss: 0.3840 - accuracy: 0.8722 - 1s/epoch - 11ms/step\n",
      "The GRU model gives us an accuracy of:  0.8722401857376099\n"
     ]
    }
   ],
   "source": [
    "output = gru_model.evaluate(testing_padded,  test_labels, verbose=2)\n",
    "print(\"The GRU model gives us an accuracy of: \", output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff5af1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
